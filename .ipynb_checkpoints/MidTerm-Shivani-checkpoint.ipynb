{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Analysis\n",
    "\n",
    "I have used lyrics dataset present here - https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading/Parsing/Tokenizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-87b91d30d662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib as mpl\n",
    "import nltk\n",
    "from math import pi\n",
    "from bokeh.io import show\n",
    "from bokeh.models import (\n",
    "    ColumnDataSource,\n",
    "    HoverTool,\n",
    "    LinearColorMapper,\n",
    "    BasicTicker,\n",
    "    PrintfTickFormatter,\n",
    "    ColorBar,\n",
    ")\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import gridplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the data\n",
    "df = pd.read_csv(\"lyrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column to keep the tokenized lyrics\n",
    "df[\"tokenized\"] = df[\"lyrics\"].apply(lambda x: \" \".join(nltk.word_tokenize(str(x).decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot to see word count in songs over the year, also a bar chart to see group over the years and see the mean song length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Count in Songs Across The Year \n",
    "sample = df.copy()\n",
    "sample[\"word_count\"] = sample[\"lyrics\"].apply(lambda x: len(x.split()))\n",
    "data = ColumnDataSource(data=dict(year=sample[\"year\"],count=sample[\"word_count\"]))\n",
    "scatter = figure(title=\"word count over the years\")\n",
    "scatter.circle('year','count',source=data)\n",
    "\n",
    "#mean word count\n",
    "test = sample.copy()\n",
    "test = test.groupby('year')[\"word_count\"].agg({'word_count_mean':'mean'}).reset_index()\n",
    "test['year'] = test['year'].astype(str)\n",
    "years=list(test['year'].unique())\n",
    "cd = ColumnDataSource(test)\n",
    "#year_cmap = factor_cmap('year', palette=Spectral5, factors=sorted(test.year.unique()))\n",
    "bar = figure(x_range=years,title=\"word count over the years\")\n",
    "bar.vbar(x='year',top='word_count_mean',width=1,source=cd)#, line_color=year_cmap, fill_color=year_cmap)\n",
    "grid = gridplot([[scatter, bar]])\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeatMap for occurence of word love in genre vs year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HeatMap for occurence of word Love in genre vs year\n",
    "\n",
    "import functools\n",
    "\n",
    "df = df.dropna() \n",
    "df = df[df.year > 1960]\n",
    "\n",
    "count = df.groupby(['genre','year'],as_index=False).count()\n",
    "count = count[['genre','year','song']]\n",
    "\n",
    "love = pd.DataFrame(df.groupby(['year','genre'])['lyrics'].apply(lambda x: x[x.str.contains('love')].count()))\n",
    "love.reset_index(inplace=True)\n",
    "love.columns = [ 'year','genre','love_lyrics']\n",
    "love = love.fillna(0)\n",
    "\n",
    "temp = [count, love]\n",
    "love_freq = functools.reduce(lambda left,right: pd.merge(left,right,on=['genre','year'], how='outer'), temp)\n",
    "love_freq['love_lyrics'] = love_freq['love_lyrics'] / love_freq['song']\n",
    "\n",
    "love_freq['year'] = love_freq['year'].astype(str)\n",
    "\n",
    "years = list(love_freq.year.unique())\n",
    "genre = list(love_freq.genre.unique())\n",
    "\n",
    "colors = [\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\", \"#933b41\", \"#550b1d\"]\n",
    "mapper = LinearColorMapper(palette=colors, low=love_freq.love_lyrics.min(), high=love_freq.love_lyrics.max())\n",
    "\n",
    "source = ColumnDataSource(love_freq)\n",
    "\n",
    "TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
    "\n",
    "p = figure(title=\"Heat Map for word Love in Song Genres across the Years\",\n",
    "           x_range=years, y_range=list(reversed(genre)),\n",
    "           x_axis_location=\"above\", plot_width=900, plot_height=400,\n",
    "           tools=TOOLS, toolbar_location='below')\n",
    "\n",
    "p.grid.grid_line_color = None\n",
    "p.axis.axis_line_color = None\n",
    "p.axis.major_tick_line_color = None\n",
    "p.axis.major_label_text_font_size = \"5pt\"\n",
    "p.axis.major_label_standoff = 0\n",
    "p.xaxis.major_label_orientation = pi / 3\n",
    "\n",
    "p.rect(x='year', y='genre', width=1, height=1,\n",
    "       source=source,\n",
    "       fill_color={'field': 'love_lyrics', 'transform': mapper},\n",
    "       line_color=None)\n",
    "\n",
    "color_bar = ColorBar(color_mapper=mapper, major_label_text_font_size=\"5pt\",\n",
    "                     ticker=BasicTicker(desired_num_ticks=len(colors)),\n",
    "                     formatter=PrintfTickFormatter(format=\"%d%%\"),\n",
    "                     label_standoff=6, border_line_color=None, location=(0, 0))\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "\n",
    "show(p)      # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "Heatmap - \"Country, Jazz, Pop\" has the most songs with word \"love\" in it and has consistent over years. while metal, electronic and rock has the least. \n",
    "Word Count with year - We can see that avg song length has reduced with years. and was its peak during 1995 and 2000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I have grouped rock songs together and compared them with a arbitary corpora \"brown corpus\". To make a comparison between the two corpora, I define an arbitrary measure of \"Rockness\", analogous to \"Metalness\" given here. \n",
    "http://www.degeneratestate.org/posts/2016/Apr/20/heavy-metal-and-natural-language-processing-part-1/. \n",
    "Finally, I have plotted rockness vs length of token for top 1000 \"rock words\". Also, I have plotted freq of these top words in rock songs vs freq in  non-rock songs to see if these are specifically \"rock words\" or are common words in songs. These plots are connected through brushing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "## calculating token freq for rock songs and the brown corpus\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "rock = df[df[\"genre\"] == \"Rock\"]\n",
    "rock_token_freq = defaultdict(int)\n",
    "count=0\n",
    "tokens = rock['tokenized']\n",
    "print len(tokens)\n",
    "\n",
    "for i in tokens:\n",
    "    words = i.split()\n",
    "    for w in words:\n",
    "        if len(w)>2 and w not in stop_words:\n",
    "            rock_token_freq[w.lower()] += 1\n",
    "            \n",
    "#brown corpus\n",
    "words = [w.lower() for w in nltk.corpus.brown.words()]\n",
    "eng_token_freq = defaultdict(int)\n",
    "count=0\n",
    "print len(words)\n",
    "for w in words:\n",
    "    eng_token_freq[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculatin rockness score\n",
    "rockness = {}\n",
    "from __future__ import division\n",
    "from math import log\n",
    "import operator \n",
    "\n",
    "n_rock = sum(rock_token_freq.itervalues())\n",
    "n_all_eng = sum(eng_token_freq.itervalues())\n",
    "\n",
    "rock_token_freq = {k:v for k,v in rock_token_freq.iteritems() if v > 5}\n",
    "\n",
    "for w in rock_token_freq:\n",
    "    if eng_token_freq[w]>0:\n",
    "        rockness[w] = log( (rock_token_freq[w] / n_rock) / (eng_token_freq[w] / n_all_eng))\n",
    "        \n",
    "rockness_sorted = sorted(rockness.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "rockness_score=[]\n",
    "length=[]\n",
    "word=[]\n",
    "\n",
    "toprockwords = rockness_sorted[:1000]\n",
    "for key,value in dict(toprockwords).iteritems():\n",
    "    if len(key) >2:\n",
    "        rockness_score.append(value)\n",
    "        length.append(len(key))\n",
    "        word.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating nonrock song token freq\n",
    "\n",
    "nonrock = df[df[\"genre\"]!=\"Rock\"]\n",
    "nonrock_token_freq = defaultdict(int)\n",
    "count=0\n",
    "tokens = nonrock['tokenized']\n",
    "print len(tokens)\n",
    "for i in tokens:\n",
    "    words = i.split()\n",
    "    for w in words:\n",
    "        if len(w)>2 and w not in stop_words:\n",
    "            nonrock_token_freq[w.lower()] += 1\n",
    "\n",
    "n_nonrock = sum(nonrock_token_freq.values())\n",
    "\n",
    "#rock vs nonrock\n",
    "common = dict(toprockwords).keys()\n",
    "rock_freq=[]\n",
    "nonrock_freq=[]\n",
    "common_w=[]\n",
    "\n",
    "for w in common:\n",
    "    if w in nonrock_token_freq:\n",
    "        common_w.append(w)\n",
    "        rock_freq.append(np.log(rock_token_freq[w]/n_rock))\n",
    "        nonrock_freq.append(np.log(nonrock_token_freq[w]/n_nonrock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in common:\n",
    "    if w in nonrock_token_freq:\n",
    "        common_w.append(w)\n",
    "        rock_freq.append(np.log(rock_token_freq[w]/n_rock))\n",
    "        nonrock_freq.append(np.log(nonrock_token_freq[w]/n_nonrock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "import numpy as np\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "N = 1000\n",
    "\n",
    "xc = np.random.random(size=N) * 100\n",
    "yc = np.random.random(size=N) * 100\n",
    "#radii = np.random.random(size=N) * 1.5\n",
    "colors = [\"#%02x%02x%02x\" % (r, g, 150) for r, g in zip(np.floor(50+2*xc), np.floor(30+2*yc))]\n",
    "\n",
    "\n",
    "TOOLS = \"box_select,lasso_select,help\"\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    rockness_score=rockness_score,\n",
    "    length=length,\n",
    "    vocab=word,\n",
    "    rock_freq=rock_freq,\n",
    "    nonrock_freq=nonrock_freq,\n",
    "    colors=colors\n",
    "))\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"word\", \"@vocab\"),\n",
    "])\n",
    "\n",
    "hover2 = HoverTool(tooltips=[\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"word\", \"@vocab\"),\n",
    "])\n",
    "\n",
    "p = figure(tools=[TOOLS,hover])\n",
    "p.scatter('rockness_score', 'length',size=10,color='colors',source=source)\n",
    "p.xaxis.axis_label = 'rockness score'\n",
    "p.yaxis.axis_label = 'length of the word'\n",
    "p.title.text = \"Rockness Vs Length\"\n",
    "\n",
    "q = figure(tools=[TOOLS,hover2])\n",
    "q.scatter('rock_freq', 'nonrock_freq',size=10,color='colors',source=source)\n",
    "q.xaxis.axis_label = 'frequency in rock songs'\n",
    "q.yaxis.axis_label = 'frequency in other songs'\n",
    "q.title.text = \"Rock Frequency vs NonRock Frequency For Top Rock Words\"\n",
    "\n",
    "s = gridplot([[p,q]])\n",
    "show(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation - <br>\n",
    "\n",
    "Relationship from freq of rock words in rock songs vs non-rock songs is linear and directly proportional. Words classified as rock words have almost same frequency in non-rock songs as well. Also, we can see that there is not a lot relation between length of a word and its frequency of occurence. \n",
    "Also, the rockness of the word decreases with increase in length of the word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering By Artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also clustered top 100 artist based on their lyrics. (concatenated there lyrics and then calculated vector for each artist using tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get top artist\n",
    "n = 100\n",
    "top_artist = df[['artist']].groupby(['artist'])['artist'].count().reset_index(name='count').sort_values(['count'], ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "def combine_vectors(vectors):\n",
    "    return normalise(np.sum(vectors, axis=0))\n",
    "\n",
    "artist = df[df.artist.isin(top_artist.artist.values)]\n",
    "artist = artist.groupby('artist').agg({'tokenized': 'sum'}).reset_index()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=ENGLISH_STOP_WORDS,\n",
    "    lowercase=True,\n",
    "    max_df=0.7,\n",
    "    min_df=0.001,\n",
    "    norm=None\n",
    ")\n",
    "\n",
    "artist[\"vectors_unnormalised\"] = list(vectorizer.fit_transform(artist.tokenized.values).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "colors = np.array([x for x in ('#00f', '#0f0', '#f00', '#0ff', '#f0f', '#ff0')])\n",
    "X = artist[\"vectors_unnormalised\"].tolist()\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "data2D = pca.transform(X)\n",
    "kmeans = cluster.KMeans(4)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = top_artist.artist.values\n",
    "#print names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = figure(width=550, height=550, title='Clustering By Artist')\n",
    "source = ColumnDataSource(data=dict(data=X,x=data2D[:,0],y=data2D[:,1],color=colors[kmeans.labels_].tolist()))\n",
    "plot.scatter('x', 'y', color =\"color\",source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
